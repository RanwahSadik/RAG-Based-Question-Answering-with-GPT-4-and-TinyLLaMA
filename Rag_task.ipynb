{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kBeiZB26H_V_",
        "outputId": "0279dc37-9527-40a0-c839-85c7a1f8824d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.75.0)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Collecting unstructured\n",
            "  Downloading unstructured-0.17.2-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting pdfminer.six\n",
            "  Downloading pdfminer_six-20250416-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.52)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.31)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from unstructured) (5.2.0)\n",
            "Collecting filetype (from unstructured)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting python-magic (from unstructured)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from unstructured) (5.3.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from unstructured) (3.9.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from unstructured) (4.13.4)\n",
            "Collecting emoji (from unstructured)\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting dataclasses-json (from unstructured)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting python-iso639 (from unstructured)\n",
            "  Downloading python_iso639-2025.2.18-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting langdetect (from unstructured)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting rapidfuzz (from unstructured)\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting backoff (from unstructured)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting unstructured-client (from unstructured)\n",
            "  Downloading unstructured_client-0.33.0-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from unstructured) (1.17.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unstructured) (5.9.5)\n",
            "Collecting python-oxmsg (from unstructured)\n",
            "  Downloading python_oxmsg-0.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.11/dist-packages (from unstructured) (1.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six) (43.0.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.17.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->unstructured) (2.6)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->unstructured)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json->unstructured)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.11/dist-packages (from html5lib->unstructured) (1.17.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from html5lib->unstructured) (0.5.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured) (2024.11.6)\n",
            "Collecting olefile (from python-oxmsg->unstructured)\n",
            "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting aiofiles>=24.1.0 (from unstructured-client->unstructured)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting eval-type-backport>=0.2.0 (from unstructured-client->unstructured)\n",
            "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (1.6.0)\n",
            "Collecting pypdf>=4.0 (from unstructured-client->unstructured)\n",
            "  Downloading pypdf-5.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.22)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured-0.17.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20250416-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_iso639-2025.2.18-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.6/167.6 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Downloading python_oxmsg-0.0.2-py3-none-any.whl (31 kB)\n",
            "Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured_client-0.33.0-py3-none-any.whl (181 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.4/181.4 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-5.4.0-py3-none-any.whl (302 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=70e2213f02ff6ff910d230ac1c73f614085258233b331c06ea0224132767d95f\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
            "Successfully built langdetect\n",
            "Installing collected packages: filetype, rapidfuzz, python-magic, python-iso639, pypdf, olefile, mypy-extensions, marshmallow, langdetect, faiss-cpu, eval-type-backport, emoji, backoff, aiofiles, typing-inspect, python-oxmsg, unstructured-client, pdfminer.six, dataclasses-json, unstructured\n",
            "Successfully installed aiofiles-24.1.0 backoff-2.2.1 dataclasses-json-0.6.7 emoji-2.14.1 eval-type-backport-0.2.2 faiss-cpu-1.10.0 filetype-1.2.0 langdetect-1.0.9 marshmallow-3.26.1 mypy-extensions-1.0.0 olefile-0.47 pdfminer.six-20250416 pypdf-5.4.0 python-iso639-2025.2.18 python-magic-0.4.27 python-oxmsg-0.0.2 rapidfuzz-3.13.0 typing-inspect-0.9.0 unstructured-0.17.2 unstructured-client-0.33.0\n"
          ]
        }
      ],
      "source": [
        "pip install langchain openai faiss-cpu unstructured pdfminer.six"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqYQQQdfJeiA"
      },
      "outputs": [],
      "source": [
        "!pip install pymupdf sentence-transformers faiss-cpu llama-cpp-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U langchain-community\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd0WtsPcIoev",
        "outputId": "916e1ea3-7d4c-499c-c875-a70ae5174d37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.52)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.23 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.23)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.31)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.19.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain-community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain-community) (2.11.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (2.33.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv, httpx-sse, pydantic-settings, langchain-community\n",
            "Successfully installed httpx-sse-0.4.0 langchain-community-0.3.21 pydantic-settings-2.9.1 python-dotenv-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tiktoken\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_MYu7fvoJRRs",
        "outputId": "b0688028-c0b8-4f74-8734-93f6d422afb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using GPT Model"
      ],
      "metadata": {
        "id": "xMV4gwQ0zdxU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the PDF"
      ],
      "metadata": {
        "id": "ds8g_WTvIW10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"/content/A_Recommender_System_for_Healthy_Food_Choices_Building_a_Hybrid.pdf\")\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "GB-c6_U4IU_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split the Text into Chunks"
      ],
      "metadata": {
        "id": "Ms5thStbIx50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "splitter = CharacterTextSplitter(chunk_size=600, chunk_overlap=100)\n",
        "docs = splitter.split_documents(documents)\n"
      ],
      "metadata": {
        "id": "qk4igX8DIt8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embed and Store in FAISS"
      ],
      "metadata": {
        "id": "UoaIUAVGI3ic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\""
      ],
      "metadata": {
        "id": "9ialFFK7JFPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "embedding = OpenAIEmbeddings()\n",
        "db = FAISS.from_documents(docs, embedding)\n",
        "retriever = db.as_retriever()"
      ],
      "metadata": {
        "id": "LwkiWdy-I1SB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82883108-f457-4c39-9544-471da6ffd224"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-68621ca36582>:4: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
            "  embedding = OpenAIEmbeddings()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG Chain"
      ],
      "metadata": {
        "id": "UVDzW155JawI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-4-0125-preview\", temperature=0.3)\n",
        "rag_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n"
      ],
      "metadata": {
        "id": "5_m-cHuLJWU0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "299cbdb8-8236-4e5c-a6fe-7b8bfca2c8f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-e020b8d461aa>:5: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm = ChatOpenAI(model_name=\"gpt-4-0125-preview\", temperature=0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\n",
        "    \"What is a hybrid recommender system and how is it used?\",\n",
        "    \"How Does the system deal with user calorie intake?\",\n",
        "    \"What evaluation metrics were used in the study?\"\n",
        "]\n",
        "\n",
        "for q in questions:\n",
        "    print(f\"Q: {q}\")\n",
        "    print(\"A:\", rag_chain.invoke({\"query\": q}))\n",
        "    print(\"-\" * 80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQDJgSQ3JeX1",
        "outputId": "1eca190c-aa5c-4e51-a859-b152eb27d3eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: What is a hybrid recommender system and how is it used?\n",
            "A: {'query': 'What is a hybrid recommender system and how is it used?', 'result': 'A hybrid recommender system is an approach that combines multiple recommendation techniques to optimize the process of making suggestions to users. These systems aim to leverage the strengths and mitigate the weaknesses of individual recommendation methods, such as content-based and collaborative filtering, to improve the accuracy and relevance of recommendations. By integrating features of both (or multiple) types of recommender systems, hybrid models can provide more personalized and accurate suggestions.\\n\\nIn the context of the research on \"A Recommender System for Healthy Food Choices,\" a hybrid recommender system is used to recommend healthier food options to individuals. This system combines content-based filtering, which focuses on the properties of items (in this case, recipes) and user preferences, with collaborative filtering, which relies on the behavior and preferences of a community of users to make recommendations. The hybrid approach aims to predict what a user will like based on both their own preferences and the preferences of similar users, while also considering specific health factors such as calorie counts and nutritional composition of recipes.\\n\\nThe hybrid model described in the research incorporates calorie counts into ingredient decomposition to develop a recommendation model that not only aligns with the user\\'s taste preferences but also offers healthier food choices. This approach addresses the limitations of purely content-based or collaborative systems by providing recommendations that are both desirable to the user and healthier options, potentially influencing users towards making healthier dietary choices without sacrificing their personal taste preferences.'}\n",
            "--------------------------------------------------------------------------------\n",
            "Q: How Does the system deal with user calorie intake?\n",
            "A: {'query': 'How Does the system deal with user calorie intake?', 'result': 'The system deals with user calorie intake by first calculating the user\\'s Basal Metabolic Rate (BMR) based on their height, weight, age, gender, and activity level. The Harris-Benedict equation is used for this calculation. Once the BMR is estimated, it is then multiplied by a lifestyle multiplication factor that corresponds to the user\\'s activity level (e.g., Sedentary, Lightly Active, Moderately Active, Very Active, Extra Active) to determine the approximate daily calorie intake needed to maintain the user\\'s current body weight. This process allows the system to tailor recipe recommendations to ensure they align with the user\\'s dietary needs and restrictions, including their calorie intake requirements. \\n\\nFor example, if a user is categorized as \"Moderately Active,\" their BMR is multiplied by 1.55 to calculate their daily calorie intake. This calculated calorie intake is then used to filter and recommend recipes that meet the user\\'s energy needs, ensuring the recommendations support a healthy diet that aligns with the user\\'s lifestyle and nutritional goals.'}\n",
            "--------------------------------------------------------------------------------\n",
            "Q: What evaluation metrics were used in the study?\n",
            "A: {'query': 'What evaluation metrics were used in the study?', 'result': 'The study used recall, precision, and accuracy as the evaluation metrics to assess the performance of the recommender systems. Recall is the ratio of relevant items recommended to the number of all relevant items, precision is the ratio of relevant items recommended to the number of all items recommended, and accuracy is the fraction of correct predictions made by the system.'}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using llama Model"
      ],
      "metadata": {
        "id": "HsgI4lo5zTkN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmNn8J6yJl9p"
      },
      "source": [
        "##**Extract and Chunk PDF**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT1mmZuEJtUn",
        "outputId": "cd99c22d-0590-45fb-c4f8-f5d36efb65d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of chunks: 23\n",
            "Example chunk:\n",
            "  A Recommender System for Healthy Food Choices: Building a Hybrid Model for Recipe Recommendations using Big Data Sets Pallavi Chavan, Brian Thoms, Jason Isaacs CSU Channel Islands pallaviamod.chavan289@myci.csuci.edu, brian.thoms@csuci.edu, jason.isaacs@csuci.edu Abstract Advances in Big Data analytics and machine learning have offered intangible benefits across many areas of one’s health. One such area is a move towards healthier lifestyle choices such as one’s diet. Recommender systems apply techniques that can filter information and narrow that information down based on user preferences or user needs and help users choose what information is relevant. Commonly adopted across e-commerce sites, social networking and entertainment industries, recommender systems can also support nutrition-based health management, offering individuals more food options, not only based on one’s preferred tastes but also on one’s dietary needs and restrictions. This research presents the design, implementation and evaluation of three recommender systems using content-based, collaborative filtering and hybrid recommendation models within the nutrition domain. 1. Introduction Today’s Internet is a global network of computers, where data and information can be accessed and manipulated with relative ease. The Internet’s widespread adoption has ushered in the era of Big Data, referring to the exponentially increasing amounts of data at high volume, high velocity and great variety. While this tremendous influx of data has intrinsic value, it maintains little utility until it can be processed and analyzed for relevant information [1]. Until such time, most of the benefits of Big Data remain untapped and hidden for practical use. Even within open datasets, it is highly inefficient and next to impossible for any individual to uncover the potential of the information stored within these massive data stores. More efficient ways of processing Big Data require advanced computing, which helps to process the data, extract important data features and analyze the data for patterns and\n"
          ]
        }
      ],
      "source": [
        "import fitz  # PyMuPDF\n",
        "import re\n",
        "\n",
        "# Load PDF file and extract text\n",
        "pdf_path = \"/content/A_Recommender_System_for_Healthy_Food_Choices_Building_a_Hybrid (1).pdf\"\n",
        "doc = fitz.open(pdf_path)\n",
        "\n",
        "full_text = \"\"\n",
        "for page in doc:\n",
        "    full_text += page.get_text()\n",
        "\n",
        "# Split the text into 300-word chunks\n",
        "def chunk_text(text, chunk_size=300):\n",
        "    words = re.split(r'\\s+', text)\n",
        "    chunks = [' '.join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]\n",
        "    return chunks\n",
        "\n",
        "chunks = chunk_text(full_text)\n",
        "print(f\"Number of chunks: {len(chunks)}\")\n",
        "print(\"Example chunk:\\n\", chunks[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9S9E8PcnKGUl"
      },
      "source": [
        "##Generate Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456,
          "referenced_widgets": [
            "ff3567d797b843e8bf48749baae0615b",
            "fa79c3d443334c4a8ef71a3b98593c6f",
            "58ef636ff3ae450baeb1eb625dfb9cc5",
            "427320b3ec2243d98c7a07bc36435664",
            "47ba2f05a0dd43f5ae24e30fd626e451",
            "31a6573602f143279df6fa9567dc4d8a",
            "56971753aecb4f5099bded683b0d2a33",
            "3d013d6cf03c46049f96ebe73a82e98f",
            "826ea4eb0c204dcba7beaa1d4523bdee",
            "ca1807cc3a3f4c7c9eccde5ea8f24297",
            "073755e992b84fab9b8c9c58536ac96e",
            "9a3ead0b02214c5b9f95ad39a21ba723",
            "90d2df77aac74df6879b92cb3c3494bf",
            "99b77af0e8e6471db0ea7ce9daad2294",
            "616b16cf4a454cb18afab5ca401529ae",
            "5b4de7801a94404f8148e6faf1976aa8",
            "f6b9249b9c0b4a9595d77e30f392c906",
            "986820dd3af54a499ba4a1b49e00af0f",
            "c1a906e7cb12467686a3848357b4c3ca",
            "1772182463e24b17b7b6bf6b47ca114a",
            "7d00f23299934b979840aa61f73308f4",
            "21501fde77bd4dd6bed1eb437ce8c403",
            "6e89836f00614f79889b3b98d2b1abcd",
            "3ed613db1f2c4105aa13bf031c028881",
            "85c94235a877458aad7c18ce1bfc7165",
            "1e4a4090ea99428e9293496339f61339",
            "7b31acbecde143feb5eb654f0b38e0d8",
            "b19045adc9854c5eb40ab0fefc76d6c5",
            "dee1bf97ce644243b1e4135cb1a998e3",
            "deeec1bbad9847a9abe665ece625b1ba",
            "11da6f7b9e0948989c0081c524e61984",
            "678af9e39ded41a3b966c66417a53c10",
            "769ccc76a03d467497ea2f3d2cffedfc",
            "aa24b24a4a94471e986f2b7ef20ba72f",
            "c79a29575197439881095f4c52585ec5",
            "3042f6cd02b541589fc5d2391de0f2aa",
            "0f8c6515561e4f859811f767490cc0e3",
            "79bc41c539874c21a3a817c7a1bf3350",
            "edfe50d5f4c449fe8882a03637a31d7c",
            "bd0d4eec51024e4bbd4ccebfcd4e8b04",
            "27af91e4f2c84268befe81615d81de59",
            "3314d70b70cd4ec6bc8a058a7ef17bcf",
            "d122e34e59b044e1a75abab10ccbdcfe",
            "9ecccfa7bf194709bcd85e656b01bdb1",
            "8da7c1bb29b94909a17c790d6eac52b4",
            "5a3a3673c43a45d9be2f39c615167a25",
            "49bee51c4265495a97347b1ad93788c4",
            "d305632a7cf74814b99655cd65ae4812",
            "6203a2a4c15740f2bdd055ccfe882ba5",
            "c85cae408e924d95af837d396319d66f",
            "1e8a9c8d98844633935abba60e65d146",
            "81d405f0ebf94eb5a21aeed195683099",
            "cc0cd13e39ce45e0a354e479e924c7c4",
            "7b3a79cb8597432bbd1a7e6a20a4319a",
            "7c2b2115d3d84b0796047db32aac1583",
            "efcc47d6d82b4ee089a85b9c900f063d",
            "df777d94502b429e87e2970ebece74c8",
            "c06c33a6ba7a4a49a65f97bf48a6ccc9",
            "a862b4e666794db396afd6ca995085db",
            "be71766b9e3449f39c745f6e3fdf9ccf",
            "ab0392343ece48bca295457a73423c79",
            "dbd6e52c27a74419be1efdbacbabce3c",
            "a5d0788158d843eb8573260b0e3fdacd",
            "ed8d7cfa958d4d61b55ade4feee3240b",
            "136c795326804d5593fdaac590463804",
            "e0a9ac85f5de4c719591fca7ec588b48",
            "c4e8011238e643c0897816bac0c85eb1",
            "839ae14ed6624a4ca0e07cafe209cb4e",
            "2be94032133743f0a8363b6a43302fcd",
            "d3f9cb7027f94b80849c044a116f93c4",
            "5bad20ca17bd42739d21502b22850211",
            "ce231ae947ea4a5c9d639a9b846a8b57",
            "1928be3a44694d48a6c2685d0076ea22",
            "82cc0a9f811748bbbf278ba2f6b682c9",
            "19f130bae2964b7aaf1761f53f795bfe",
            "1ddb7c7e3d58432d9deb1a368e6e0315",
            "49fda191d3e9493a927ac03b51509a81",
            "d2793d10d5574422b7f3d62cacd89e52",
            "8398b0ea8cdc48bfb5b8c3781ec0f895",
            "3c72c589127b45f78dba8318415abf90",
            "b680a94618ed4ec0b8be1eaf00eabe3d",
            "b9f88529ea27493bb258daa57babef60",
            "d42f92bd1ab141ff8e177a3266c540d0",
            "20d655c276f647cd9037ac78d6cb626b",
            "c57a8e128ed94ebd85b952172ea99dd6",
            "5b12ad8074374cce9ae9635228bd7e60",
            "086b95e40dcb44e394fa914400fe2939",
            "840bf6b2842840d1a182ca4ede859435",
            "3b7169df57ef498c8af1bbb7d3ef6431",
            "e5312879cb2140ee99f19886dcf4d86a",
            "c9542172daf24916a8c4b6c122790e06",
            "e5841cceb1094cd49f4c7e400d14cbd2",
            "11dcef95631647208ca549cabb0379f0",
            "a6c71456f6d44d50a986b14eba782302",
            "e759d0636b35478cb54d4f982bf06264",
            "5112d03b445147cd9f31e0eaf92c4ce4",
            "39f96c274d8d48ac82b6c6ff48ef9631",
            "b04acb49bea048cdbc5aa1f639a6e6ba",
            "924233ec0b3a46cb9854b0b117b0e98b",
            "5fa39e20f4d94408b0eb64b3632b8796",
            "a514cb60f79049fcaecae31962fbd50d",
            "f1a7c0f6e3a14afa96080eca752db263",
            "39d5e81d638a4e259bed47bb230d078a",
            "3884cb6c9de54f95a5271272756d7daf",
            "0d57348ebd744ddc8190bfcae7c5b28d",
            "34a91bfc91964e3786f5deee4e042c50",
            "af158c5dbd5f4613ac64a49cd8e1954c",
            "2de356acebab40319f79b2587c69a2f0",
            "6279f9b38eee499e84742c65bd68f882",
            "06e70443000f4be088bcc92499ec14e5",
            "0fbf9a3fce1d40cb82e654a134d4d918",
            "a51698e249ee419c9aa748ded2f8bdcf",
            "6b727b68801d41b4a6b88c9502933387",
            "368e7e9db44e4c0a82fa67693f001cee",
            "86c4860a4d7d43f6a6d06839cf75c0cb",
            "35b86eaad4ae40b181264e718d260901",
            "e3e806ba2ea640a38c83fd5f44074935",
            "9ab47d04021740d0960fbf494b91d34a",
            "49c8cec370284977bd288ca92fc42bf6",
            "fae9aae4ad0c46da91b08aafafde714c",
            "678a251c90d74c129e5bd14e47ad6e3e",
            "8ef53583691045dca43f834e9f6a568e",
            "fb5165909b5c4eff88a7d73340b116b5",
            "a5415db82b44438696246c5578218c32",
            "3f14626ea08249539aef5052675d5d51",
            "50e76bdf0c9a4398a2a39e4ccd3d5c10",
            "3a2fb5a3c903433b9b9b6f75dc58fad8",
            "ede812bb45de433d8939a106cabb6358",
            "46fe151f54b8433fb86a783d682e4c71",
            "5b0a6f52b0f14b8cbae8c420bd27850b",
            "804294a229e44ec4996e65485966c0c4",
            "4fb0196b91464d9199265ef9f1fbc710"
          ]
        },
        "id": "VMiL2fEAKLRM",
        "outputId": "d538308a-7a34-4a6f-ba9a-646e012df91a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff3567d797b843e8bf48749baae0615b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a3ead0b02214c5b9f95ad39a21ba723",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e89836f00614f79889b3b98d2b1abcd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa24b24a4a94471e986f2b7ef20ba72f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8da7c1bb29b94909a17c790d6eac52b4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "efcc47d6d82b4ee089a85b9c900f063d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c4e8011238e643c0897816bac0c85eb1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2793d10d5574422b7f3d62cacd89e52",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b7169df57ef498c8af1bbb7d3ef6431",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5fa39e20f4d94408b0eb64b3632b8796",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0fbf9a3fce1d40cb82e654a134d4d918",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ef53583691045dca43f834e9f6a568e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "embeddings = model.encode(chunks, show_progress_bar=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLK1aicXMwLH"
      },
      "source": [
        "##Store Embeddings in FAISS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "En983SlsMKcL"
      },
      "outputs": [],
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "embeddings_np = np.array(embeddings).astype(\"float32\")\n",
        "\n",
        "# Create FAISS index\n",
        "index = faiss.IndexFlatL2(embeddings_np.shape[1])\n",
        "index.add(embeddings_np)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a6qCYOkM9DB"
      },
      "source": [
        "##Load LLaMA Model and Define RAG Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "2124bafd8d84401ba643ef18c1f33eff",
            "46c1ac44350e440c8c9fafaedf12908a",
            "ac565fbd76d04d4693592f45605a0813",
            "ec8dad612ac248ad8b1e3ff4bd105ecd",
            "7694e091bf18471cb9a743b55197e035",
            "9d3d45cbcd9c4e519e6cc9c874b05eb9",
            "de008c66aef846f3848182aa86ec0526",
            "3c2f17603b07401ca1f6441c8fa72d86",
            "25af2deee43344d798c9bc1fdc27be66",
            "b2e14e148a834c4faec6adb972fd849a",
            "7c2e20e217b54b259f471f69b90994b0"
          ]
        },
        "id": "o2pJHSpuejws",
        "outputId": "16d5f410-cddf-49f9-ad6c-53dab5767944"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2124bafd8d84401ba643ef18c1f33eff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tinyllama-1.1b-chat-v1.0.Q8_0.gguf:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model downloaded to: /content/tinyllama-1.1b-chat-v1.0.Q8_0.gguf\n"
          ]
        }
      ],
      "source": [
        "# Download the model\n",
        "from huggingface_hub import hf_hub_download\n",
        "model_name = \"TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF\"\n",
        "model_file = \"tinyllama-1.1b-chat-v1.0.Q8_0.gguf\"\n",
        "model_path = hf_hub_download(repo_id=model_name, filename=model_file, local_dir=\"/content\")\n",
        "print(f\"Model downloaded to: {model_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaNGmVLpM283",
        "outputId": "96748979-1bcb-4d35-f5cb-fc6135d7fb5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded successfully\n"
          ]
        }
      ],
      "source": [
        "# Load the LLaMA model\n",
        "from llama_cpp import Llama\n",
        "llm = Llama(model_path=model_path, n_ctx=2048, verbose=False)\n",
        "print(\"Model loaded successfully\")\n",
        "\n",
        "# Define retrieval + generation function (unchanged)\n",
        "def rag_ask(question, k=3):\n",
        "    question_embedding = model.encode([question]).astype(\"float32\")\n",
        "    # Search for top-k similar chunks\n",
        "    distances, indices = index.search(question_embedding, k)\n",
        "    context = \"\\n\\n\".join([chunks[i] for i in indices[0]])\n",
        "\n",
        "    # Build the prompt for the LLM\n",
        "    prompt = f\"Context:\\n{context}\\n\\nQuestion: {question}\\nAnswer:\"\n",
        "    output = llm(prompt, max_tokens=200, stop=[\"Question:\"])\n",
        "    print(\" Answer:\\n\", output[\"choices\"][0][\"text\"].strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8-nQPl9bW-L",
        "outputId": "2ecd4de5-0084-4645-d327-a86a2f83b95c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Answer:\n",
            " In this research, a hybrid recommender system is used. A hybrid recommender system combines content-based and collaborative filtering techniques. The content-based model generates predictions based on the user’s diet and ingredient choices. The collaborative filtering model is used to filter predictions based on user preferences and diet restrictions. A gradual process is used to adjust the weights of the content-based model and collaborative filtering model. The results show that even if the performance of the hybrid model has increased slightly compared to collaborative filtering, it's more efficient in terms of recommendation because it takes into account user preferences and diet restrictions.\n",
            " Answer:\n",
            " The system does not deal with user calorie intake as it considers it only in the context of the user's preferences and dietary habits. It does not have access to the user's actual calorie intake and does not use calorie intake as a factor in recommendation.\n",
            " Answer:\n",
            " The study used various evaluation metrics including recall, precision, accuracy, and content-based model detailed in Table 3.\n"
          ]
        }
      ],
      "source": [
        "rag_ask(\"What is a hybrid recommender system and how is it used?\")\n",
        "rag_ask(\"How does the system deal with user calorie intake?\")\n",
        "rag_ask(\"What evaluation metrics were used in the study?\")"
      ]
    }
  ]
}